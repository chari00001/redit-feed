import numpy as np
import json
from sklearn.metrics.pairwise import cosine_similarity
from typing import List, Dict, Any, Optional
from collections import defaultdict, Counter
from app.features import TagFeatureExtractor
from app.content_analyzer import SmartContentAnalyzer
from app.db import database
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.cluster import MiniBatchKMeans

class EnhancedRecommender:
    def __init__(self):
        self.posts = []
        self.post_ids = []
        self.tag_extractor = TagFeatureExtractor()
        self.content_analyzer = SmartContentAnalyzer()
        self.feature_matrix = None
        self.user_interactions = {}
        self.user_profiles = {}
        self.post_analysis = {}
        self.vectorizer = None
        
    async def load_user_profiles_from_db(self, user_id: Optional[int] = None):
        """
        user_tag_interactions tablosundan kullanÄ±cÄ± profillerini yÃ¼kler
        """
        print("ğŸ‘¤ KullanÄ±cÄ± profilleri veritabanÄ±ndan yÃ¼kleniyor...")
        
        query = "SELECT * FROM user_tag_interactions"
        if user_id:
            query += f" WHERE user_id = {user_id}"
            
        interactions = await database.fetch_all(query)
        
        self.user_profiles = {}
        
        for interaction in interactions:
            uid = interaction['user_id']
            if uid not in self.user_profiles:
                self.user_profiles[uid] = {
                    'tag_preferences': defaultdict(float),
                    'interaction_summary': defaultdict(int),
                    'total_interactions': 0
                }
            
            tag = interaction['tag']
            interaction_type = interaction['interaction_type']
            count = interaction['interaction_count']
            
            # EtkileÅŸim tÃ¼rÃ¼ne gÃ¶re aÄŸÄ±rlÄ±k
            weight_map = {'view': 1.0, 'like': 3.0, 'comment': 4.0, 'share': 5.0}
            score = count * weight_map.get(interaction_type, 1.0)
            
            self.user_profiles[uid]['tag_preferences'][tag] += score
            self.user_profiles[uid]['interaction_summary'][interaction_type] += count
            self.user_profiles[uid]['total_interactions'] += count
            
        print(f"âœ… {len(self.user_profiles)} kullanÄ±cÄ±nÄ±n profili yÃ¼klendi.")

    async def fit(self, posts: List[Dict[str, Any]], use_content_analysis: bool = True):
        """
        GeliÅŸmiÅŸ makine Ã¶ÄŸrenmesi ile Ã¶neri modelini eÄŸitir
        """
        self.posts = posts
        self.post_ids = [post["id"] for post in posts]
        
        print(f"ğŸš€ {len(posts)} post iÃ§in geliÅŸmiÅŸ Ã¶neri sistemi eÄŸitiliyor...")
        
        if use_content_analysis and len(posts) > 3:
            # Ä°Ã§erik analizi yap
            analysis_results = self.content_analyzer.analyze_posts(posts)
            self.post_analysis = analysis_results['post_analysis']
            
            # Enhanced tags ile yeni post listesi oluÅŸtur
            enhanced_posts = []
            for post in posts:
                enhanced_post = post.copy()
                post_analysis = self.post_analysis.get(post['id'], {})
                enhanced_post['tags'] = post_analysis.get('enhanced_tags', post.get('tags', []))
                enhanced_posts.append(enhanced_post)
            
            # Enhanced tags ile feature matrix oluÅŸtur
            self.feature_matrix = self.tag_extractor.fit_transform(enhanced_posts)
        else:
            # Sadece mevcut etiketlerle
            self.feature_matrix = self.tag_extractor.fit_transform(posts)
        
        self.vectorizer = self.tag_extractor.vectorizer
        
        # TÃ¼m kullanÄ±cÄ± profillerini yÃ¼kle
        await self.load_user_profiles_from_db()
        
        print(f"âœ… Ã–neri sistemi eÄŸitildi. {self.feature_matrix.shape[1]} Ã¶zellik oluÅŸturuldu.")
    
    def update_user_interactions(self, user_id: int, post_id: int, interaction_type: str, weight: float = 1.0):
        """
        KullanÄ±cÄ± etkileÅŸimini gÃ¼nceller ve kullanÄ±cÄ± profilini yeniden hesaplar
        """
        if user_id not in self.user_interactions:
            self.user_interactions[user_id] = []
        
        # EtkileÅŸimi kaydet
        interaction = {
            'post_id': post_id,
            'interaction_type': interaction_type,
            'weight': weight,
            'timestamp': np.datetime64('now')
        }
        self.user_interactions[user_id].append(interaction)
        
        # KullanÄ±cÄ± profilini gÃ¼ncelle
        self._update_user_profile(user_id)
    
    def _update_user_profile(self, user_id: int):
        """
        KullanÄ±cÄ±nÄ±n etkileÅŸimlerinden ilgi profilini oluÅŸturur
        """
        if user_id not in self.user_interactions:
            return
        
        tag_weights = defaultdict(float)
        cluster_weights = defaultdict(float)
        total_weight = 0
        
        # EtkileÅŸim aÄŸÄ±rlÄ±klarÄ±
        interaction_weights = {
            'view': 1.0,
            'like': 3.0,
            'comment': 4.0,
            'share': 5.0
        }
        
        for interaction in self.user_interactions[user_id]:
            post_id = interaction['post_id']
            interaction_type = interaction['interaction_type']
            base_weight = interaction_weights.get(interaction_type, 1.0)
            
            # Bu postun etiketlerini bul
            post_data = next((p for p in self.posts if p['id'] == post_id), None)
            if not post_data:
                continue
            
            # Enhanced tags kullan
            if post_id in self.post_analysis:
                tags = self.post_analysis[post_id].get('enhanced_tags', [])
                cluster_id = self.post_analysis[post_id].get('cluster_id', -1)
            else:
                tags = post_data.get('tags', [])
                if isinstance(tags, str):
                    try:
                        tags = json.loads(tags)
                    except:
                        tags = []
                cluster_id = -1
            
            # Etiket aÄŸÄ±rlÄ±klarÄ±nÄ± gÃ¼ncelle
            for tag in tags:
                tag_weights[tag] += base_weight
                total_weight += base_weight
            
            # KÃ¼me aÄŸÄ±rlÄ±klarÄ±nÄ± gÃ¼ncelle
            if cluster_id != -1:
                cluster_weights[cluster_id] += base_weight
        
        # Normalize et
        if total_weight > 0:
            for tag in tag_weights:
                tag_weights[tag] /= total_weight
            for cluster in cluster_weights:
                cluster_weights[cluster] /= total_weight
        
        # KullanÄ±cÄ± profilini kaydet
        self.user_profiles[user_id] = {
            'tag_preferences': dict(tag_weights),
            'cluster_preferences': dict(cluster_weights),
            'total_interactions': len(self.user_interactions[user_id]),
            'last_updated': np.datetime64('now')
        }
    
    async def recommend_for_user(self, user_id: int, top_n: int = 10,
                               exclude_seen: bool = True) -> List[Dict[str, Any]]:
        """
        KullanÄ±cÄ±ya kiÅŸiselleÅŸtirilmiÅŸ Ã¶neriler sunar
        """
        # EÄŸer kullanÄ±cÄ± profili hafÄ±zada yoksa, o kullanÄ±cÄ±yÄ± anlÄ±k olarak yÃ¼kle
        if user_id not in self.user_profiles:
            print(f"ğŸ‘¤ KullanÄ±cÄ± {user_id} profili hafÄ±zada deÄŸil. VeritabanÄ±ndan yÃ¼kleniyor...")
            await self.load_user_profiles_from_db(user_id=user_id)

        if user_id not in self.user_profiles:
            # VeritabanÄ±ndan da bulunamadÄ±ysa yeni kullanÄ±cÄ±dÄ±r
            print(f"âš ï¸ KullanÄ±cÄ± {user_id} iÃ§in profil bulunamadÄ±. PopÃ¼ler gÃ¶nderiler Ã¶neriliyor.")
            return self._get_diversified_popular_posts(top_n)
        
        user_profile = self.user_profiles[user_id]
        tag_preferences = user_profile['tag_preferences']
        
        # KullanÄ±cÄ±nÄ±n daha Ã¶nce etkileÅŸimde bulunduÄŸu postlarÄ± bul
        seen_posts = set()
        if exclude_seen and user_id in self.user_interactions:
            seen_posts = {interaction['post_id'] for interaction in self.user_interactions[user_id]}
        
        # Her post iÃ§in geliÅŸmiÅŸ benzerlik skoru hesapla
        post_scores = []
        
        for i, post in enumerate(self.posts):
            post_id = post['id']
            
            # Daha Ã¶nce gÃ¶rÃ¼len postlarÄ± atla
            if post_id in seen_posts:
                continue
            
            # 1. KÄ°ÅÄ°SELLEÅTÄ°RME SKORU (Etiket ve KÃ¼me BazlÄ±)
            personalization_score = 0.0
            
            # A. Etiket uyumu
            tag_match_score = 0.0
            matched_tags = 0
            unknown_tags = 0
            
            if post_id in self.post_analysis:
                post_tags = self.post_analysis[post_id].get('enhanced_tags', [])
            else:
                post_tags = post.get('tags', [])
                if isinstance(post_tags, str):
                    try:
                        post_tags = json.loads(post_tags)
                    except:
                        post_tags = []
            
            for tag in post_tags:
                if tag in tag_preferences:
                    tag_match_score += tag_preferences[tag]
                    matched_tags += 1
                else:
                    unknown_tags += 1
            
            # EÅŸleÅŸen etiketlerin ortalama aÄŸÄ±rlÄ±ÄŸÄ±
            if matched_tags > 0:
                personalization_score += (tag_match_score / matched_tags) * 2.0 # Etiket uyumunu 2x aÄŸÄ±rlÄ±klandÄ±r
            
            # Bilinmeyen etiketler iÃ§in kÃ¼Ã§Ã¼k bir ceza
            personalization_score -= (unknown_tags / len(post_tags)) * 0.1
            
            # B. KÃ¼me uyumu (cluster_preferences kaldÄ±rÄ±ldÄ±ÄŸÄ± iÃ§in bu kÄ±sÄ±m basitleÅŸtirildi)
            cluster_id = self.post_analysis.get(post_id, {}).get('cluster_id', -1)
            
            # 2. Ã‡EÅÄ°TLÄ°LÄ°K BONUSU
            diversity_bonus = 0.0
            
            # KullanÄ±cÄ±nÄ±n az etkileÅŸimde bulunduÄŸu kÃ¼meleri tercih et
            if cluster_id != -1:
                user_cluster_interactions = sum(1 for interaction in self.user_interactions.get(user_id, [])
                                               if self.post_analysis.get(interaction['post_id'], {}).get('cluster_id') == cluster_id)
                
                # Az etkileÅŸimde bulunulan kÃ¼melere bonus ver
                if user_cluster_interactions < 2:
                    diversity_bonus += 0.3
                elif user_cluster_interactions < 5:
                    diversity_bonus += 0.1
            
            # 3. ETKÄ°LEÅÄ°M TÃœRÃœ BONUSU
            interaction_preference_bonus = 0.0
            
            # En yaygÄ±n etkileÅŸim tÃ¼rÃ¼nÃ¼ bul
            if user_profile['interaction_summary']:
                most_common_interaction = max(user_profile['interaction_summary'], key=user_profile['interaction_summary'].get)
                
                # Bu post tÃ¼rÃ¼ kullanÄ±cÄ±nÄ±n tercih ettiÄŸi etkileÅŸim tÃ¼rÃ¼ne uygun mu?
                content = post.get('content', '') or ''
                if 'comment' in most_common_interaction and len(content) > 100:
                    interaction_preference_bonus += 0.2
                elif 'like' in most_common_interaction and post.get('likes_count', 0) > 5:
                    interaction_preference_bonus += 0.15
                elif 'share' in most_common_interaction and len(post_tags) > 2:
                    interaction_preference_bonus += 0.1
            
            # 4. ZAMAN BAZLI BONUS (Yeni iÃ§eriklere hafif Ã¶ncelik)
            time_bonus = 0.0
            if hasattr(post, 'created_at') and post.get('created_at'):
                # Yeni postlara kÃ¼Ã§Ã¼k bonus ver
                time_bonus = 0.05
            
            # 5. POPÃœLERLIK SKORU (AzaltÄ±lmÄ±ÅŸ etki)
            popularity_score = 0.0
            if any([post.get('likes_count', 0), post.get('comments_count', 0), 
                   post.get('shares_count', 0), post.get('views_count', 0)]):
                popularity_score = (
                    post.get('likes_count', 0) * 0.2 +
                    post.get('comments_count', 0) * 0.3 +
                    post.get('shares_count', 0) * 0.4 +
                    post.get('views_count', 0) * 0.1
                ) / 50.0  # Daha dÃ¼ÅŸÃ¼k normalize
            
            # 6. RASTGELE Ã‡EÅÄ°TLÄ°LÄ°K FAKTÃ–RÃœ
            import random
            randomness_factor = random.uniform(-0.05, 0.05)  # KÃ¼Ã§Ã¼k rastgelelik
            
            # TOPLAM SKOR HESAPLAMA
            final_score = (
                personalization_score * 0.70 +      # Ana kiÅŸiselleÅŸtirme skoru
                diversity_bonus * 0.15 +             # Ã‡eÅŸitlilik bonusu  
                interaction_preference_bonus * 0.10 + # EtkileÅŸim tercihi
                time_bonus * 0.03 +                  # Zaman bonusu
                popularity_score * 0.02 +            # PopÃ¼lerlik (Ã§ok dÃ¼ÅŸÃ¼k)
                randomness_factor                    # Rastgelelik
            )
            
            post_scores.append((post_id, final_score, post))
        
        # Skora gÃ¶re sÄ±rala
        post_scores.sort(key=lambda x: x[1], reverse=True)
        
        # Ã‡EÅÄ°TLÄ°LÄ°K FÄ°LTRELEMESÄ° - AynÄ± kÃ¼meden Ã§ok fazla Ã¶neri verme
        recommendations = []
        cluster_counts = {}
        max_per_cluster = max(2, top_n // 3)  # Her kÃ¼meden maksimum sayÄ±sÄ±
        
        for post_id, score, post_data in post_scores:
            if len(recommendations) >= top_n:
                break
                
            # Bu postun kÃ¼mesini kontrol et
            cluster_id = self.post_analysis.get(post_id, {}).get('cluster_id', -1)
            
            # KÃ¼me limiti kontrolÃ¼
            if cluster_id != -1:
                if cluster_counts.get(cluster_id, 0) >= max_per_cluster:
                    continue  # Bu kÃ¼meden yeterince Ã¶neri var
                cluster_counts[cluster_id] = cluster_counts.get(cluster_id, 0) + 1
            
            post_copy = post_data.copy()
            post_copy['recommendation_score'] = float(score)
            post_copy['recommendation_reason'] = self._generate_recommendation_reason(user_id, post_data, score)
            recommendations.append(post_copy)
        
        # EÄŸer yeterli Ã¶neri yoksa, kalan yerleri en iyi skorlarla doldur
        if len(recommendations) < top_n:
            remaining_posts = [item for item in post_scores if item[0] not in [r['id'] for r in recommendations]]
            for post_id, score, post_data in remaining_posts[:top_n - len(recommendations)]:
                post_copy = post_data.copy()
                post_copy['recommendation_score'] = float(score)
                post_copy['recommendation_reason'] = "Genel Ã¶neri"
                recommendations.append(post_copy)
        
        # Buna raÄŸmen hala Ã¶neri yoksa, popÃ¼lerleri ekle
        if not recommendations:
            print(f"â„¹ï¸ KiÅŸiselleÅŸtirilmiÅŸ Ã¶neri bulunamadÄ±, popÃ¼ler gÃ¶nderilerle destekleniyor.")
            return self._get_diversified_popular_posts(top_n)
            
        return recommendations
    
    def _generate_recommendation_reason(self, user_id: int, post_data: Dict, score: float) -> str:
        """
        Ã–neri nedenini aÃ§Ä±klar
        """
        if user_id not in self.user_profiles:
            return "PopÃ¼ler iÃ§erik"
        
        user_profile = self.user_profiles[user_id]
        post_id = post_data['id']
        
        # Post etiketlerini al
        if post_id in self.post_analysis:
            post_tags = self.post_analysis[post_id].get('enhanced_tags', [])
        else:
            post_tags = post_data.get('tags', [])
            if isinstance(post_tags, str):
                try:
                    post_tags = json.loads(post_tags)
                except:
                    post_tags = []
        
        # KullanÄ±cÄ±nÄ±n ilgilendiÄŸi etiketlerle eÅŸleÅŸenleri bul
        matching_tags = []
        if post_tags:
            for tag in post_tags:
                if tag in user_profile['tag_preferences']:
                    matching_tags.append(tag)
        
        if matching_tags:
            # En yÃ¼ksek skorlu eÅŸleÅŸen etiketi bul
            best_match = max(matching_tags, key=lambda t: user_profile['tag_preferences'].get(t, 0))
            return f"'{best_match}' ilgi alanÄ±nÄ±za uygun"
        elif score > 0.5:
            return "YÃ¼ksek puanlÄ± iÃ§erik"
        elif len(post_tags) > 0:
            return f"'{post_tags[0]}' konusunda"
        else:
            return "Sizin iÃ§in seÃ§ildi"
    
    def _get_diversified_popular_posts(self, top_n: int = 10) -> List[Dict[str, Any]]:
        """
        Ã‡eÅŸitlendirilmiÅŸ popÃ¼ler postlarÄ± dÃ¶ndÃ¼rÃ¼r (yeni kullanÄ±cÄ±lar iÃ§in)
        """
        # PopÃ¼lerlik skoruna gÃ¶re sÄ±rala
        posts_with_scores = []
        for post in self.posts:
            popularity_score = (
                post.get('likes_count', 0) * 0.3 +
                post.get('comments_count', 0) * 0.5 +
                post.get('shares_count', 0) * 0.7 +
                post.get('views_count', 0) * 0.1
            )
            
            # Rastgele Ã§eÅŸitlilik ekle
            import random
            diversity_factor = random.uniform(0.8, 1.2)
            final_score = popularity_score * diversity_factor
            
            posts_with_scores.append((final_score, post))
        
        posts_with_scores.sort(key=lambda x: x[0], reverse=True)
        
        # Ã‡eÅŸitlilik filtresi - farklÄ± kÃ¼melerden seÃ§
        popular_posts = []
        used_clusters = set()
        max_per_cluster = max(2, top_n // 4)
        cluster_counts = {}
        
        for score, post in posts_with_scores:
            if len(popular_posts) >= top_n:
                break
                
            # KÃ¼me kontrolÃ¼
            cluster_id = self.post_analysis.get(post['id'], {}).get('cluster_id', -1)
            
            if cluster_id != -1:
                if cluster_counts.get(cluster_id, 0) >= max_per_cluster:
                    continue
                cluster_counts[cluster_id] = cluster_counts.get(cluster_id, 0) + 1
            
            post_copy = post.copy()
            post_copy['recommendation_score'] = float(score)
            post_copy['recommendation_reason'] = "PopÃ¼ler iÃ§erik"
            popular_posts.append(post_copy)
        
        # EÄŸer yeterli deÄŸilse geri kalanlarÄ± ekle
        if len(popular_posts) < top_n:
            remaining = [item for item in posts_with_scores if item[1]['id'] not in [p['id'] for p in popular_posts]]
            for score, post in remaining[:top_n - len(popular_posts)]:
                post_copy = post.copy()
                post_copy['recommendation_score'] = float(score)
                post_copy['recommendation_reason'] = "PopÃ¼ler iÃ§erik"
                popular_posts.append(post_copy)
        
        return popular_posts
    
    def _get_popular_posts(self, top_n: int = 10) -> List[Dict[str, Any]]:
        """
        PopÃ¼ler postlarÄ± dÃ¶ndÃ¼rÃ¼r (yeni kullanÄ±cÄ±lar iÃ§in)
        """
        # PopÃ¼lerlik skoruna gÃ¶re sÄ±rala
        posts_with_scores = []
        for post in self.posts:
            popularity_score = (
                post.get('likes_count', 0) * 0.3 +
                post.get('comments_count', 0) * 0.5 +
                post.get('shares_count', 0) * 0.7 +
                post.get('views_count', 0) * 0.1
            )
            posts_with_scores.append((popularity_score, post))
        
        posts_with_scores.sort(key=lambda x: x[0], reverse=True)
        
        popular_posts = []
        for score, post in posts_with_scores[:top_n]:
            post_copy = post.copy()
            post_copy['recommendation_score'] = float(score)
            popular_posts.append(post_copy)
        
        return popular_posts
    
    def get_similar_posts(self, post_id: int, top_n: int = 5) -> List[Dict[str, Any]]:
        """
        Belirli bir posta benzer postlarÄ± bulur
        """
        if post_id not in self.post_ids:
            return []
        
        # Ä°Ã§erik analizi varsa kÃ¼me bazlÄ± benzerlik
        if post_id in self.post_analysis:
            return self.content_analyzer.get_similar_posts(post_id, top_n)
        
        # Yoksa TF-IDF benzerliÄŸi
        idx = self.post_ids.index(post_id)
        post_vector = self.feature_matrix[idx]
        similarities = cosine_similarity(post_vector, self.feature_matrix).flatten()
        
        # Kendisi hariÃ§ en benzer postlarÄ± bul
        similar_indices = np.argsort(similarities)[::-1]
        similar_indices = [i for i in similar_indices if i != idx][:top_n]
        
        similar_posts = []
        for i in similar_indices:
            post = self.posts[i].copy()
            post["similarity_score"] = float(similarities[i])
            similar_posts.append(post)
        
        return similar_posts
    
    async def get_user_interest_profile(self, user_id: int) -> Dict[str, Any]:
        """
        KullanÄ±cÄ±nÄ±n ilgi profiline iliÅŸkin bir Ã¶zet dÃ¶ndÃ¼rÃ¼r.
        Veriyi doÄŸrudan user_tag_interactions tablosundan alÄ±r.
        """
        
        # KullanÄ±cÄ± profilini veritabanÄ±ndan anlÄ±k olarak yÃ¼kle
        await self.load_user_profiles_from_db(user_id=user_id)
        
        if user_id not in self.user_profiles:
            return {
                "user_id": user_id,
                "status": "new_user",
                "message": "HenÃ¼z yeterli etkileÅŸim verisi yok"
            }
        
        profile = self.user_profiles[user_id]
        
        # En Ã§ok tercih edilen etiketleri sÄ±rala
        top_tags = sorted(profile['tag_preferences'].items(), 
                              key=lambda item: item[1], 
                              reverse=True)
        
        # Profil gÃ¼cÃ¼nÃ¼ hesapla
        total_score = sum(profile['tag_preferences'].values())
        profile_strength = min(1.0, total_score / 100.0) # 100 skoru max gÃ¼Ã§ olarak kabul et
        
        return {
            "user_id": user_id,
            "status": "profile_found",
            "total_interactions": profile.get('total_interactions', 0),
            "profile_strength": profile_strength,
            "interaction_summary": profile.get('interaction_summary', {}),
            "top_interests": [
                {"tag": tag, "weight": round(weight, 3)} for tag, weight in top_tags[:15]
            ]
        }
    
    def get_topic_posts(self, cluster_id: int, top_n: int = 10) -> List[Dict[str, Any]]:
        """
        Belirli bir konudaki postlarÄ± dÃ¶ndÃ¼rÃ¼r
        """
        return self.content_analyzer.get_posts_by_topic(cluster_id, top_n)
    
    def get_topics_summary(self) -> Dict[str, Any]:
        """
        TÃ¼m konularÄ±n Ã¶zetini dÃ¶ndÃ¼rÃ¼r
        """
        if not hasattr(self.content_analyzer, 'cluster_keywords'):
            return {'topics': [], 'message': 'Ä°Ã§erik analizi henÃ¼z yapÄ±lmadÄ±'}
        
        topics = []
        for cluster_id, keywords in self.content_analyzer.cluster_keywords.items():
            # Bu konudaki post sayÄ±sÄ±nÄ± hesapla
            post_count = sum(1 for analysis in self.post_analysis.values() 
                           if analysis.get('cluster_id') == cluster_id)
            
            topics.append({
                'topic_id': cluster_id,
                'keywords': keywords[:8],
                'post_count': post_count
            })
        
        # Post sayÄ±sÄ±na gÃ¶re sÄ±rala
        topics.sort(key=lambda x: x['post_count'], reverse=True)
        
        return {
            'topics': topics,
            'total_topics': len(topics),
            'total_posts_analyzed': len(self.post_analysis)
        }
    
    def save_models(self, filepath: str = "models/"):
        """
        TÃ¼m modelleri kaydet
        """
        # Ä°Ã§erik analizÃ¶rÃ¼nÃ¼ kaydet
        self.content_analyzer.save_models(filepath)
        
        # Tag extractor'Ä± kaydet
        import joblib
        import os
        os.makedirs(filepath, exist_ok=True)
        
        if self.tag_extractor.vectorizer:
            joblib.dump(self.tag_extractor, f"{filepath}/tag_extractor.pkl")
        
        # KullanÄ±cÄ± profillerini kaydet
        user_data = {
            'user_interactions': self.user_interactions,
            'user_profiles': self.user_profiles,
            'post_analysis': self.post_analysis
        }
        joblib.dump(user_data, f"{filepath}/user_data.pkl")
        
        print(f"âœ… TÃ¼m modeller {filepath} klasÃ¶rÃ¼ne kaydedildi.")
    
    def load_models(self, filepath: str = "models/"):
        """
        KaydedilmiÅŸ modelleri yÃ¼kle
        """
        import joblib
        import os
        
        try:
            # Ä°Ã§erik analizÃ¶rÃ¼nÃ¼ yÃ¼kle
            self.content_analyzer.load_models(filepath)
            
            # Tag extractor'Ä± yÃ¼kle
            if os.path.exists(f"{filepath}/tag_extractor.pkl"):
                self.tag_extractor = joblib.load(f"{filepath}/tag_extractor.pkl")
            
            # KullanÄ±cÄ± verilerini yÃ¼kle
            if os.path.exists(f"{filepath}/user_data.pkl"):
                user_data = joblib.load(f"{filepath}/user_data.pkl")
                self.user_interactions = user_data.get('user_interactions', {})
                self.user_profiles = user_data.get('user_profiles', {})
                self.post_analysis = user_data.get('post_analysis', {})
            
            print(f"âœ… TÃ¼m modeller {filepath} klasÃ¶rÃ¼nden yÃ¼klendi.")
            return True
        except Exception as e:
            print(f"âŒ Model yÃ¼kleme hatasÄ±: {e}")
            return False 